<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>corenlp on Susie Kim</title>
    <link>https://susie-kim.github.io/tags/corenlp/</link>
    <description>Recent content in corenlp on Susie Kim</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Jan 2019 20:00:00 -0500</lastBuildDate><atom:link href="https://susie-kim.github.io/tags/corenlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using Stanford CoreNLP with R: Bigram and Trigram Analysis</title>
      <link>https://susie-kim.github.io/posts/2019-01-01-new-corenlp/</link>
      <pubDate>Tue, 01 Jan 2019 20:00:00 -0500</pubDate>
      
      <guid>https://susie-kim.github.io/posts/2019-01-01-new-corenlp/</guid>
      <description>1 . Preparation 1.1 . Install Java 1.2 . Install cleanNLP and language model 2 . Annotation Using Stanford CoreNLP 3 . Example Text Analysis: Creating Bigrams and Trigrams 3.1 . With tidytext 3.2 . Manually Creating Bigrams and Trigrams 3.3 . Example Analysis: Be + words Forget my previous posts on using the Stanford NLP engine via command and retreiving information from XML files in R…. I’ve found that everything can be done in RStudio (at least I learned more about how to work with XML in R).</description>
    </item>
    
    <item>
      <title>Working with XML-formatted text annotations in R</title>
      <link>https://susie-kim.github.io/posts/2018-05-04-working-xml/</link>
      <pubDate>Fri, 04 May 2018 10:34:40 -0500</pubDate>
      
      <guid>https://susie-kim.github.io/posts/2018-05-04-working-xml/</guid>
      <description>1 . From XML to tagged corpus 1.1 . Creating tagged text 1.2 . Rendering xml to data frame 1.3 . Creating tagged texts 2 . Example query and concordances In this post I’m documenting how to reformat the XML-formatted files outputted by the Stanford CoreNLP tool. This might not be the most elegant way to go about it, but this is something that works for me. Here, I will be using R and the XML files produced in the previous step.</description>
    </item>
    
    <item>
      <title>A guide to using the Stanford CoreNLP Tools for automatic text annotation</title>
      <link>https://susie-kim.github.io/posts/2018-04-06-guide-corenlp/</link>
      <pubDate>Fri, 06 Apr 2018 12:20:40 -0500</pubDate>
      
      <guid>https://susie-kim.github.io/posts/2018-04-06-guide-corenlp/</guid>
      <description>Stanford CoreNLP tools Parsing As the title suggests, I will guide you through how to automatically annotate raw texts using the Stanford CoreNLP in this post.
Stanford CoreNLP tools The Stanford CoreNLP is a set of natural language analysis tools written in Java programming language. It takes raw text input then tokenizes each word and parses them into the base forms of words (i.e., lemmas). The users can utilize this set of tools to further parse the text, such as tagging the parts of speech (i.</description>
    </item>
    
  </channel>
</rss>
